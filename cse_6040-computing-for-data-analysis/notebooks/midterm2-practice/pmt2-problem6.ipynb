{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Important note**! Before you turn in this lab notebook, make sure everything runs as expected:\n",
    "\n",
    "- First, restart the kernel -- in the menubar, select Kernel → Restart.\n",
    "- Then run all cells -- in the menubar, select Cell → Run All.\n",
    "\n",
    "Make sure you fill in any place that says YOUR CODE HERE or \"YOUR ANSWER HERE.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## UK Traffic Accidents\n",
    "\n",
    "In this problem, you will work with and analyze some data about accidents in the UK from 2009 to 2011. This data was derived from Kaggle.  The original dataset can be found here: https://www.kaggle.com/daveianhickey/2000-16-traffic-flow-england-scotland-wales/data.\n",
    "\n",
    "This problem has 4 exercises worth a total of 10 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Run the following code cell, which will load the modules you'll need for this problem.\n",
    "\n",
    "> **Note.** This problem involves SQLite and the `sqlite3` module. Since that module is not supported in Vocareum when using the Python 3.6 kernel, we have set this notebook to use Python 3.5. If you do any testing or prototyping on your local machine, keep in mind that you are still responsible for making your code work when submitted through the autograder on Vocareum, so be mindful of potential versioning differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.3 |Anaconda, Inc.| (default, Nov  9 2017, 00:19:18) \n",
      "[GCC 7.2.0]\n",
      "Pandas version: 0.23.4\n",
      "Numpy version: 1.13.3\n",
      "SQLite3 version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3 as db\n",
    "\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"SQLite3 version: {}\".format(db.version))\n",
    "\n",
    "from IPython.display import display\n",
    "from cse6040utils import download_all, canonicalize_tibble, tibbles_are_equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "To help with your analysis, we will first drop any record that has missing value. We will also transform the column, `Date`, to have the structure yyyy-mm-dd.  Using this transformed Date column, we will then add a `Month` column to the dataset, which you will use in the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...This may take a while...\n",
      "Downloading: https://cse6040.gatech.edu/datasets/accidents/accident_by_hour_soln.csv ...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Downloaded file 'accidents/accident_by_hour_soln.csv' has incorrect checksum: 'a9a1e61648d3cb7ca839dfafa22e3c52' instead of '46ae91224473fc2d15794716d10231ce'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-58dee299a5b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'max_dayofweek_soln.csv'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'54f0f74c9ac05880e6a5b23d5d34f11b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             'top10_location_soln.csv': '5b67bcf14fd719afe8444a00a3390c80'}\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdatapaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accidents/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#let's read the data into our environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/midterm2-practice/cse6040utils.py\u001b[0m in \u001b[0;36mdownload_all\u001b[0;34m(datasets, local_base, local_suffix, url_base, url_suffix, suffix)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0murl_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchecksum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdownload_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchecksum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchecksum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mlocal_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocal_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/midterm2-practice/cse6040utils.py\u001b[0m in \u001b[0;36mdownload_one\u001b[0;34m(filename, local_base, url_base, checksum, mkdir)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \"Downloaded file '{}' has incorrect checksum: '{}' instead of '{}'\".format(local_file,\n\u001b[1;32m     28\u001b[0m                                                                                            \u001b[0mbody_checksum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                                                                            checksum)\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'{}' is ready!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Downloaded file 'accidents/accident_by_hour_soln.csv' has incorrect checksum: 'a9a1e61648d3cb7ca839dfafa22e3c52' instead of '46ae91224473fc2d15794716d10231ce'"
     ]
    }
   ],
   "source": [
    "print('Loading dataset...This may take a while...')\n",
    "\n",
    "datasets = {'accident_by_hour_soln.csv': '46ae91224473fc2d15794716d10231ce',\n",
    "            'accidents_2009_to_2011.csv': '530ce2d51394f77a21fdd741a8ac9f0b',\n",
    "            'max_dayofweek_soln.csv': '54f0f74c9ac05880e6a5b23d5d34f11b',\n",
    "            'top10_location_soln.csv': '5b67bcf14fd719afe8444a00a3390c80'}\n",
    "datapaths = download_all(datasets, suffix='accidents/')\n",
    "\n",
    "#let's read the data into our environment\n",
    "Accidents = pd.read_csv(datapaths[\"accidents_2009_to_2011.csv\"])\n",
    "\n",
    "#we will remove any rows that has missing values\n",
    "Accidents = Accidents.dropna() \n",
    "\n",
    "#transform the Date column\n",
    "Accidents['Date'] = pd.to_datetime(Accidents['Date'], dayfirst=True, infer_datetime_format=True).dt.date\n",
    "\n",
    "#add the Month column\n",
    "Accidents['Month'] = pd.to_datetime(Accidents['Date'], dayfirst=True, infer_datetime_format=True).dt.month\n",
    "\n",
    "\n",
    "assert len(Accidents)==281765 # number of records\n",
    "assert len(Accidents.columns) == 18 # number of columns\n",
    "\n",
    "print('\\nAfter preprocessing, Accidents has {} records and {} columns'.format(len(Accidents), len(Accidents.columns)))\n",
    "print('\\nFirst 5 records of Accidents')\n",
    "Accidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's take a look the column names for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print('\\nA list of column names')\n",
    "list(Accidents) # a list of column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 0** (2 points) Using the column, `Time`, which can be of the form HH:MM or H:MM, add a new column to the dataset called `Hour`.  We will use this new column in future exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "exercise0_response",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise0",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Test Cell: exercise0 ##\n",
    "assert len(Accidents['Hour'])== 281765\n",
    "assert Accidents.iloc[0]['Hour']=='15'\n",
    "assert Accidents.iloc[100]['Hour']=='7'\n",
    "assert Accidents.iloc[1000]['Hour']=='12'\n",
    "assert Accidents.iloc[10000]['Hour']=='13'\n",
    "assert Accidents.iloc[100000]['Hour']=='15'\n",
    "assert Accidents.iloc[200000]['Hour']=='14'\n",
    "assert Accidents.iloc[281764]['Hour']=='18'\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The following code cell creates an SQLite database file named `accident.db` and copies the Pandas dataframe that we had above into the database as a table named `Accidents`.\n",
    "\n",
    "> For the exercises in this problem, you can either use the Pandas representation or the SQL representation, whichever helps you best solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Import Accidents dataframe to sqlite database\n",
    "# Connect to a database (or create one if it doesn't exist)\n",
    "\n",
    "conn = db.connect('accident.db')\n",
    "Accidents.to_sql('Accidents', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Using SQL we can see the first 5 records of `Accidents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query('SELECT * FROM Accidents LIMIT 5', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 1** (1 point) Determine the number of accidents that occur for each hour of the day.  Order the number of accidents in descending order. Save your result in a table named **`accident_by_hour`** with the columns named **`Hour`** and **`Num_of_Accidents`**, which is the number of accidents during that hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "exercise1_response",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE\n",
    "#\n",
    "\n",
    "# Show your solution:\n",
    "display(accident_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise1",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Test Cell: exercise1 ##\n",
    "# Read what we believe is the exact result\n",
    "accident_by_hour_soln = pd.read_csv(datapaths['accident_by_hour_soln.csv'])\n",
    "\n",
    "# Check that we got a data frame of the expected shape:\n",
    "assert 'accident_by_hour' in globals(), \"You need to store your results in a dataframe named `accident_by_hour`.\"\n",
    "assert type(accident_by_hour) is type(pd.DataFrame()), \"`accident_by_hour` does not appear to be a Pandas dataframe.\"\n",
    "assert len(accident_by_hour) == len(accident_by_hour_soln), \"The number of rows of `accident_by_hour` does not match our solution.\"\n",
    "assert set(accident_by_hour.columns) == set(['Hour', 'Num_of_Accidents']), \"Your table does not have the right set of columns.\"\n",
    "\n",
    "assert tibbles_are_equivalent(accident_by_hour.astype('int64'), accident_by_hour_soln)\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 2** (3 points) Suppose we are interested in determining which day of the week had the most accidents in a particular year-month pair.\n",
    "\n",
    "For each year and month, report the day of the week that had the largest number of accidents. Your result should be in ascending order by years then months, i.e., 2009-2011 for the year and 1-12 for the month. Save your result in a table called **`max_dayofweek`**.\n",
    "\n",
    "Your table should contain the following columns: {`'Year'`, `'Month'`, `'Day_of_Week'`, `'Num_of_Accidents'`}.\n",
    "\n",
    "For example, a row of this table might be `{2009, 1, 6, XXXX}`, where `XXXX` is the number of accidents observed in January 2009 on Friday. (In this data, days of the week are numbered starting at Sunday equals one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "exercise2_response",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE\n",
    "#\n",
    "\n",
    "# Show your solution:\n",
    "display(max_dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise2",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Test Cell: exercise2 ##\n",
    "# Read what we believe is the exact result\n",
    "max_dayofweek_soln = pd.read_csv(datapaths['max_dayofweek_soln.csv'])\n",
    "\n",
    "# Check that we got a data frame of the expected shape:\n",
    "assert 'max_dayofweek' in globals(), \"You need to store your results in a dataframe named `max_dayofweek`.\"\n",
    "assert type(max_dayofweek) is type(pd.DataFrame()), \"`max_dayofweek` does not appear to be a Pandas dataframe.\"\n",
    "assert len(max_dayofweek) == len(max_dayofweek_soln), \"The number of rows of `max_dayofweek` does not match our solution.\"\n",
    "assert set(max_dayofweek.columns) == set(['Year', 'Month', 'Day_of_Week', 'Num_of_Accidents']), \"Your table does not have the right set of columns.\"\n",
    "\n",
    "assert tibbles_are_equivalent(max_dayofweek, max_dayofweek_soln)\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 3** (4 points). Find the top 9 locations that had the most accidents. Report the **`Road_Surface_Conditions`** and the count of accidents under that condition. Store your result in table, **`top9_locations`**, which should contain the following columns:\n",
    "\n",
    "{`'Location_Easting_OSGR'`, `'Location_Northing_OSGR'`, `'Road_Surface_Conditions'`, `'Num_of_Accidents'`}\n",
    "\n",
    "> **Note.** We define a location by (`Location_Easting_OSGR`, `Location_Northing_OSGR`), i.e., Local British coordinates x-value, Local British coordinates y-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "exercise3_response",
     "locked": false,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE\n",
    "#\n",
    "\n",
    "# Show your solution:\n",
    "display(top9_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise3",
     "locked": true,
     "points": "4",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Test Cell: exercise3 ##\n",
    "# Read what we believe is the exact result\n",
    "top9_locations_soln = pd.read_csv(datapaths['top10_location_soln.csv'])\n",
    "\n",
    "# Check that we got a data frame of the expected shape:\n",
    "assert 'top9_locations' in globals(), \"You need to store your results in a dataframe named `top9_locations`.\"\n",
    "assert type(top9_locations) is type(pd.DataFrame()), \"`top9_locations` does not appear to be a Pandas dataframe.\"\n",
    "assert len(top9_locations) == len(top9_locations_soln), \"The number of rows of `top9_locations` does not match our solution.\"\n",
    "assert set(top9_locations.columns) == set(['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Road_Surface_Conditions', 'Num_of_Accidents']), \"Your table does not have the right set of columns.\"\n",
    "\n",
    "assert tibbles_are_equivalent(top9_locations, top9_locations_soln)\n",
    "print(\"\\n(Passed!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Some cleanup code\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "** Fin ** You've reached the end of this problem. Don't forget to restart the kernel and run the entire notebook from top-to-bottom to make sure you did everything correctly. If that is working, try submitting this problem. (Recall that you *must* submit and pass the autograder to get credit for your work.)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
