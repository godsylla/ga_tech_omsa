{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 4 \n",
    "\n",
    "For this problem, you will be asked to create a dimensionality reduction technique used in the pre-processing step for pattern-classification and other machine learning applications. The modifications you will make to this notebook will test your ability to implement an algorithm you may not have seen before.\n",
    "\n",
    "Our goal is to develop a linear transformation method that is commonly used for dimensionality reduction like PCA (Principal component analysis). In contrast to PCA, we will implement a “supervised” technique that computes the directions  that will represent the axes that maximize the separation between multiple classes. By the end of this problem you will be able to reduce the dimensions of a $d$-dimensional dataset by projecting it onto a $(k)$-dimensional subspace (where $k<d$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Let's load the data first\n",
    "\n",
    "We have loaded the required dataset for you in the code below. Go ahead and run the cell. \n",
    "\n",
    "In the following dataset - there are 4 numerical columns - `col1, col2, col3, col4` and one `class` column that signifies the class label for each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimesion of dataset: (149, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     col1  col2  col3  col4  class\n",
       "144   6.7   3.0   5.2   2.3      3\n",
       "145   6.3   2.5   5.0   1.9      3\n",
       "146   6.5   3.0   5.2   2.0      3\n",
       "147   6.2   3.4   5.4   2.3      3\n",
       "148   5.9   3.0   5.1   1.8      3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../resource/asnlib/publicdata/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore')\n",
    "r = 2 #rounding factor\n",
    "df = pd.read_csv('problem4_input.csv')\n",
    "\n",
    "X = df[['col1', 'col2', 'col3', 'col4']].values\n",
    "y = df['class'].values\n",
    "\n",
    "print(\"Dimesion of dataset: {}\".format(df.shape))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Plotting Histograms of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32e4561a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from plot_utils import plot_hist, plot_step\n",
    "plot_hist(X, y, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "There are 3 unique classes in the dataset. By just looking at these histograms, we can see that the `col3` and `col4` are better suited as potential features to separate between the three classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Important Note\n",
    "\n",
    "This notebook contains **hidden test cells** which will test your solution on a larger dataset (more rows and class labels). Make sure your solution is generic. \n",
    "\n",
    "To help you understand how that larger dataset looks like, you can run the below cells to get a preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I0</th>\n",
       "      <th>PA500</th>\n",
       "      <th>HFS</th>\n",
       "      <th>DA</th>\n",
       "      <th>Area</th>\n",
       "      <th>A/DA</th>\n",
       "      <th>Max IP</th>\n",
       "      <th>DR</th>\n",
       "      <th>P</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>524.794072</td>\n",
       "      <td>0.187448</td>\n",
       "      <td>0.032114</td>\n",
       "      <td>228.800228</td>\n",
       "      <td>6843.598481</td>\n",
       "      <td>29.910803</td>\n",
       "      <td>60.204880</td>\n",
       "      <td>220.737212</td>\n",
       "      <td>556.828334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330.000000</td>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.265290</td>\n",
       "      <td>121.154201</td>\n",
       "      <td>3163.239472</td>\n",
       "      <td>26.109202</td>\n",
       "      <td>69.717361</td>\n",
       "      <td>99.084964</td>\n",
       "      <td>400.225776</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>551.879287</td>\n",
       "      <td>0.232478</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>264.804935</td>\n",
       "      <td>11888.391830</td>\n",
       "      <td>44.894903</td>\n",
       "      <td>77.793297</td>\n",
       "      <td>253.785300</td>\n",
       "      <td>656.769449</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380.000000</td>\n",
       "      <td>0.240855</td>\n",
       "      <td>0.286234</td>\n",
       "      <td>137.640111</td>\n",
       "      <td>5402.171180</td>\n",
       "      <td>39.248524</td>\n",
       "      <td>88.758446</td>\n",
       "      <td>105.198568</td>\n",
       "      <td>493.701813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>362.831266</td>\n",
       "      <td>0.200713</td>\n",
       "      <td>0.244346</td>\n",
       "      <td>124.912559</td>\n",
       "      <td>3290.462446</td>\n",
       "      <td>26.342127</td>\n",
       "      <td>69.389389</td>\n",
       "      <td>103.866552</td>\n",
       "      <td>424.796503</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           I0     PA500       HFS          DA          Area       A/DA  \\\n",
       "0  524.794072  0.187448  0.032114  228.800228   6843.598481  29.910803   \n",
       "1  330.000000  0.226893  0.265290  121.154201   3163.239472  26.109202   \n",
       "2  551.879287  0.232478  0.063530  264.804935  11888.391830  44.894903   \n",
       "3  380.000000  0.240855  0.286234  137.640111   5402.171180  39.248524   \n",
       "4  362.831266  0.200713  0.244346  124.912559   3290.462446  26.342127   \n",
       "\n",
       "      Max IP          DR           P  class  \n",
       "0  60.204880  220.737212  556.828334      2  \n",
       "1  69.717361   99.084964  400.225776      2  \n",
       "2  77.793297  253.785300  656.769449      2  \n",
       "3  88.758446  105.198568  493.701813      2  \n",
       "4  69.389389  103.866552  424.796503      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preview = pd.read_csv('test_input_small.csv')\n",
    "test_preview.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preview.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 1** (0 points): Computing the $d$-dimensional mean vectors.\n",
    "\n",
    "Complete the `calculate_mean_vector(X,y)` function where - \n",
    "1. `X` = $ n \\times d$ matrix of input features, where $n$ = number of data points, $d$ = number of features\n",
    "2. `y` = a vector of length $n$ denoting class labels for the $n$ data points\n",
    "\n",
    "The function will return a $k \\times d$ matrix (2d numpy array) where $k$ = number of unique class. The order in which means appear should be as follows:\n",
    "\n",
    "$$ \\begin{bmatrix} \n",
    "\\vec\\mu_{class \\, 1} \\\\\n",
    "\\vec\\mu_{class \\,  2} \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "\\vec\\mu_{class \\, k}\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "**Important Note**: \n",
    "- Notebook contains **hidden test cells** which will test your solution on a larger dataset (more rows and class labels). Make sure your solution is generic. \n",
    "\n",
    "- We will test your solution rounding it to two decimal place. You **do not** need to round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.00408163, 3.41632653, 1.46530612, 0.24489796],\n",
       "       [5.936     , 2.77      , 4.26      , 1.326     ],\n",
       "       [6.588     , 2.974     , 5.552     , 2.026     ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_mean_vector(X,y):\n",
    "    #Initiate a blank numpy.ndarray object\n",
    "    mean_vectors = np.zeros((len(set(y)),X.shape[1]))\n",
    "\n",
    "    for idx, cl in enumerate(set(y)):\n",
    "        mean_vectors[idx]= np.mean(X[y==cl], axis=0)\n",
    "\n",
    "    return mean_vectors\n",
    "\n",
    "mean_vectors = calculate_mean_vector(X,y)\n",
    "mean_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "dummy_ex1",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "Passed dummy test cell\n",
      "Note : There are hidden test cells that run on a totally different but identical dataset\n"
     ]
    }
   ],
   "source": [
    "## Dummy Test Cell 1\n",
    "\n",
    "student_answer = np.round(calculate_mean_vector(X,y),r)\n",
    "# print(f'Your answer : \\n{student_answer}')\n",
    "\n",
    "teachers_answer = np.round(np.array([[5.00408163, 3.41632653, 1.46530612, 0.24489796],\n",
    "                            [5.936     , 2.77      , 4.26      , 1.326     ],\n",
    "                            [6.588     , 2.974     , 5.552     , 2.026     ]]),r)\n",
    "# print(f'Teachers answer : \\n{teachers_answer}')\n",
    "\n",
    "assert np.array_equal(student_answer, teachers_answer), \"Check the answer\"\n",
    "\n",
    "print(\"*********\")\n",
    "print(\"Passed dummy test cell\")\n",
    "print(\"Note : There are hidden test cells that run on a totally different but identical dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test_ex1",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 2** (6 points): Computing estimate of Covariance Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now, we will compute the two $d\\times d$-dimensional matrices: The within-class and the between-class estimates of covariance matrix.\n",
    "\n",
    "#### 2.1 Within-class (3 points)\n",
    "\n",
    "Complete the function `get_S_W_matrix(X, y)` that returns the within-class estimate of covariance matrix $S_W$. \n",
    "\n",
    "$$ S_w = \\sum_{i=1}^{k}S_i$$\n",
    "\n",
    "$$ \\textit{where } \\, \\,  S_i = \\sum_{\\textbf x \\epsilon D_i} (\\textbf {x} - \\textbf{m}_i)(\\textbf {x} - \\textbf{m}_i)^t  \\, \\, \\,  \\textit{(covariance matrix estimate for every class 'i')}$$\n",
    "\n",
    "$$ \\textbf{m}_i = \\frac{1}{n_i}\\sum_{\\textbf x \\epsilon D_i} \\textbf {x}  $$\n",
    "\n",
    "$D_i$ are data points labeled as class $i$. \n",
    "$n_i$ is the number of datapoints in class $i$. \n",
    "$k$ is the number of unique classes in the dataset. \n",
    "$d$ is the number of features.\n",
    "\n",
    "Note that $\\bf x$ and $\\bf m_i$ are vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X - mean_vectors[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 4)\n",
      "(50, 4)\n",
      "(50, 4)\n",
      "[[38.94718367 13.67513469 24.62013878  5.65982041]\n",
      " [13.67513469 17.02813878  8.1253551   4.91688163]\n",
      " [24.62013878  8.1253551  27.21582041  6.25072653]\n",
      " [ 5.65982041  4.91688163  6.25072653  6.17362449]]\n"
     ]
    }
   ],
   "source": [
    "def get_S_W_matrix(X,y):\n",
    "    S_W = np.zeros((X.shape[1],X.shape[1]))\n",
    "\n",
    "    ###\n",
    "    # Calculate the mean vectors\n",
    "    mean_vectors = calculate_mean_vector(X, y)\n",
    "    \n",
    "    S_cl_to_sum = []\n",
    "    for idx, cl in enumerate(set(y)):\n",
    "        # filter on only the X points associated w/ the corresponding class y\n",
    "        X_di = X[y==cl]\n",
    "        \n",
    "        # focus on the mean vector associated with class y\n",
    "        m_i = mean_vectors[idx]\n",
    "        \n",
    "        diff_vec = X_di - m_i\n",
    "        print(diff_vec.shape)\n",
    "        S_cl = (diff_vec.T.dot(diff_vec))\n",
    "        S_cl_to_sum.append(S_cl)\n",
    "        \n",
    "    for S in S_cl_to_sum:\n",
    "        S_W = np.add(S, S_W)\n",
    "    ###\n",
    "    \n",
    "    return S_W\n",
    "\n",
    "S_W = get_S_W_matrix(X,y)\n",
    "print(S_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "dummy_ex2_1",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 4)\n",
      "(50, 4)\n",
      "(50, 4)\n",
      "Your answer : \n",
      "[[38.95 13.68 24.62  5.66]\n",
      " [13.68 17.03  8.13  4.92]\n",
      " [24.62  8.13 27.22  6.25]\n",
      " [ 5.66  4.92  6.25  6.17]]\n",
      "Teachers answer \n",
      "[[38.95 13.68 24.62  5.66]\n",
      " [13.68 17.03  8.13  4.92]\n",
      " [24.62  8.13 27.22  6.25]\n",
      " [ 5.66  4.92  6.25  6.17]]\n",
      "*********\n",
      "Passed dummy test cell\n",
      "Note : There are hidden test cells that run on a totally different but identical dataset\n"
     ]
    }
   ],
   "source": [
    "## Dummy Test Cell 2.1\n",
    "\n",
    "student_answer_ex2 = np.round(get_S_W_matrix(X,y),r)\n",
    "print(f'Your answer : \\n{student_answer_ex2}')\n",
    "assert (type(student_answer_ex2)==np.ndarray), \"Check the data type of your result\"\n",
    "\n",
    "teachers_answer_ex2 = np.round(np.array([[38.94718367, 13.67513469, 24.62013878,  5.65982041],\n",
    "                                         [13.67513469, 17.02813878,  8.1253551 ,  4.91688163],\n",
    "                                         [24.62013878,  8.1253551 , 27.21582041,  6.25072653],\n",
    "                                         [ 5.65982041,  4.91688163,  6.25072653,  6.17362449]]),r)\n",
    "print(f'Teachers answer \\n{teachers_answer_ex2}')\n",
    "\n",
    "assert np.array_equal(student_answer_ex2, teachers_answer_ex2), \"Check the answer\"\n",
    "\n",
    "print(\"*********\")\n",
    "print(\"Passed dummy test cell\")\n",
    "print(\"Note : There are hidden test cells that run on a totally different but identical dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test_ex2_1",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### 2.2 Between-class covariance matrix estimate (3 points)\n",
    "\n",
    "Complete the function `get_S_B_matrix(X,y)` which returns the between-class estimate of covariance matrix $S_B$.\n",
    "\n",
    "$$ S_B = \\sum_{i}^{k} N_i (\\textbf {m}_i - \\textbf{m})(\\textbf {m}_i - \\textbf{m})^t  \\, \\, \\,  \\textit{(covariance matrix estimate for every class 'i')}$$\n",
    "\n",
    "where $\\bf m$ is the overall mean and $\\textbf{m}_i$ and $N_i$ are the sample mean and sizes of the respective classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.84832215, 3.05100671, 3.77449664, 1.20536913])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62.66489686 -19.19238302 163.39348539  70.61152187]\n",
      " [-19.19238302  10.78421022 -55.0015296  -22.047687  ]\n",
      " [163.39348539 -55.0015296  431.04726684 184.53967615]\n",
      " [ 70.61152187 -22.047687   184.53967615  79.60208021]]\n"
     ]
    }
   ],
   "source": [
    "def get_S_B_matrix(X,y):\n",
    "    \n",
    "    ###\n",
    "    S_B = np.zeros((X.shape[1], X.shape[1]))\n",
    "    \n",
    "    # Calculate the mean vectors and overall mean\n",
    "    mean_vectors = calculate_mean_vector(X, y)\n",
    "    overall_mean = np.mean(X, axis=0).reshape(1, X.shape[1])\n",
    "    \n",
    "    Sb_to_sum = []\n",
    "    for idx, cl in enumerate(set(y)):\n",
    "        # Get the sample size for class cl\n",
    "        N_i = len(X[y==cl])\n",
    "        \n",
    "        # focus on the mean vector associated with class y\n",
    "        m_i = mean_vectors[idx]\n",
    "        \n",
    "        diff_vec = m_i - overall_mean\n",
    "        Sb = np.dot(N_i*diff_vec.T, diff_vec)\n",
    "        Sb_to_sum.append(Sb)\n",
    "        \n",
    "    for S in Sb_to_sum:\n",
    "        S_B = np.add(S, S_B)\n",
    "    ###\n",
    "    \n",
    "    return S_B\n",
    "\n",
    "S_B = get_S_B_matrix(X,y)\n",
    "print(S_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "dummy_ex2_2",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "Passed dummy test cell\n",
      "Note : There are hidden test cells that run on a totally different but identical dataset\n"
     ]
    }
   ],
   "source": [
    "## Dummy Test Cell 2.2\n",
    "student_answer_ex2_2 = np.round(get_S_B_matrix(X,y),r)\n",
    "# print(f'Your answer : \\n{student_answer_ex2_2}')\n",
    "\n",
    "assert (type(student_answer_ex2_2)==np.ndarray), \"Check the data type of your result\"\n",
    "\n",
    "teachers_answer_ex2_2 = np.round(np.array([ [62.66489686, -19.19238302, 163.39348539,  70.61152187],\n",
    "                                            [-19.19238302,  10.78421022, -55.0015296 , -22.047687],\n",
    "                                            [163.39348539, -55.0015296 , 431.04726684, 184.53967615],\n",
    "                                            [ 70.61152187, -22.047687  , 184.53967615,  79.60208021]]),r)\n",
    "# print(f'Teachers answer : \\n{teachers_answer_ex2_2}')\n",
    "\n",
    "assert np.array_equal(student_answer_ex2_2, teachers_answer_ex2_2), \"Check the answer\"\n",
    "\n",
    "print(\"*********\")\n",
    "print(\"Passed dummy test cell\")\n",
    "print(\"Note : There are hidden test cells that run on a totally different but identical dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test_ex2_2",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 3:** (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Main idea: \n",
    "\n",
    "From the 2 scatter matrix above, we can solve the generalized eigenvalue problem for the matrix $S^{−1}_WS_B$ to computes the directions that will represent the axes that maximize the separation between multiple classes.\n",
    "\n",
    "We are not only interested in merely projecting the data into a subspace that improves the class separability, but also reduces the dimensionality of our feature space, (where the eigenvectors will form the axes of this new feature subspace). However, the eigenvectors only define the directions of the new axis, since they all have the same unit length 1.\n",
    "\n",
    "In order to decide which eigenvector(s) we want to drop for our lower-dimensional subspace, we have to take a look at the corresponding eigenvalues of the eigenvectors. Roughly speaking, the eigenvectors with the lowest eigenvalues bear the least information about the distribution of the data, and those are the ones we want to drop.\n",
    "\n",
    "The common approach is to rank the eigenvectors from highest to lowest corresponding to their eigenvalues and choose the top eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### For this exercise, there are 2 tasks:\n",
    "\n",
    "##### Given Input: Within-class & Between-class estimate of covariance matrices\n",
    "\n",
    "1. Calculate eigenvalue and eigenvector from matrix $S^{−1}_WS_B$ (See [numpy.linalg.eig](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html) )\n",
    "\n",
    "2. Return eigen_list: a list of [eigenvalue, eigenvector, variance_explained] sorted from high to low based on eigenvalue. \n",
    "    Here is how to calculate [variance_explained](https://stats.stackexchange.com/questions/31908/what-is-percentage-of-variance-in-pca/31911).\n",
    "\n",
    "\n",
    "##### Output: eigen_list as a numpy ndarray object\n",
    "\n",
    "    [ [eigenvalue_1, eigenvector_1, variance_explained_1],\n",
    "\n",
    "      ..., \n",
    "\n",
    "      [eigenvalue_n, eigenvector_n, variance_explained_n] ]\n",
    "\n",
    "**Note**: eigenvector is a list of number. Sample output should look like the picture below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "![alt text](Ex4.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues:  [ 3.18745794e+01  2.76937486e-01 -6.26858233e-16  3.10312741e-15] \n",
      "\n",
      "eigenvectors:  [[-0.20511216 -0.38692895  0.54633986  0.7139522 ]\n",
      " [-0.00835164 -0.58911633  0.25447583 -0.76688608]\n",
      " [ 0.7145727  -0.03630892  0.02342374 -0.6982255 ]\n",
      " [-0.79036335  0.41273135  0.42222368 -0.16341898]] \n",
      "\n",
      "explained variance:  [0.9913864876958728, 0.008613512304127149, 9.651573885530934e-17, -1.949700335913353e-17] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_eigen_list(S_W,S_B):\n",
    "    ###\n",
    "    input_matrix = (np.linalg.inv(S_W)).dot(S_B)\n",
    "    values, vectors = np.linalg.eig(input_matrix)\n",
    "    print('eigenvalues: ', values, '\\n')\n",
    "    \n",
    "    true_vectors = []\n",
    "    for i in range(len(vectors)):\n",
    "        col_vector = []\n",
    "        for vec in vectors:\n",
    "            col_vector.append(vec[i])\n",
    "        true_vectors.append(col_vector)\n",
    "    true_vectors = np.array(true_vectors)\n",
    "    print('eigenvectors: ', true_vectors, '\\n')\n",
    "    \n",
    "    eigenval_sum = np.sum(values)\n",
    "    \n",
    "    zipped = list(zip(values, true_vectors))\n",
    "    zipped_sorted = sorted(zipped, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    eigen_list = []\n",
    "    for val, vec in zipped_sorted: \n",
    "        explained_variance = val/eigenval_sum\n",
    "        eigen_list.append([val, vec, explained_variance])\n",
    "    print('explained variance: ', [ev[2] for ev in eigen_list], '\\n')\n",
    "    \n",
    "    return np.array(eigen_list)\n",
    "    ###\n",
    "\n",
    "eigen_list = get_eigen_list(S_W,S_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "dummy_ex3",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 4)\n",
      "(50, 4)\n",
      "(50, 4)\n",
      "eigenvalues:  [ 3.18745794e+01  2.76937486e-01 -6.26858233e-16  3.10312741e-15] \n",
      "\n",
      "eigenvectors:  [[-0.20511216 -0.38692895  0.54633986  0.7139522 ]\n",
      " [-0.00835164 -0.58911633  0.25447583 -0.76688608]\n",
      " [ 0.7145727  -0.03630892  0.02342374 -0.6982255 ]\n",
      " [-0.79036335  0.41273135  0.42222368 -0.16341898]] \n",
      "\n",
      "explained variance:  [0.9913864876958728, 0.008613512304127149, 9.651573885530934e-17, -1.949700335913353e-17] \n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "not equal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9635877c9605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_answer_ex3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteachers_answer_ex3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"not equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_answer_ex3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteachers_answer_ex3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"not equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*********\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: not equal"
     ]
    }
   ],
   "source": [
    "## Dummy Test Cell 3\n",
    "\n",
    "student_answer_ex3 = get_eigen_list(get_S_W_matrix(X,y),get_S_B_matrix(X,y))\n",
    "# print(f'Your answer : \\n{student_answer_ex3}')\n",
    "\n",
    "teachers_answer_ex3 = np.array([[31.874579396957305, np.array([-0.20511216, -0.38692895,  0.54633986,  0.7139522 ]), 99.13865],\n",
    "                                [0.27693748627003545, np.array([-0.00835164, -0.58911633,  0.25447583, -0.76688608]), 0.86135],\n",
    "                                [0.0, np.array([ 0.75474, -0.22471, -0.19941, -0.26944]), 0.0],\n",
    "                                [0.0, np.array([ 0.75474, -0.22471, -0.19941, -0.26944]), 0.0]])\n",
    "# print(f'Teachers answer : \\n{teachers_answer_ex3}')\n",
    "\n",
    "assert (type(student_answer_ex3))==(type(teachers_answer_ex3)), \"check the type of your result, should be a numpy.ndarray object\"\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(len(teachers_answer_ex3[i])):\n",
    "#         print(student_answer_ex3[i][j], \"- your answer\")\n",
    "#         print(teachers_answer_ex3[i][j],\"- solution\",\"\\n*****\")\n",
    "        if (type(student_answer_ex3[i][j])) == np.ndarray:\n",
    "            try:\n",
    "                assert np.array_equal(np.round(student_answer_ex3[i][j],r),np.round(teachers_answer_ex3[i][j],r)),\"not equal\"\n",
    "            except: \n",
    "                assert np.array_equal(np.round(student_answer_ex3[i][j],r)*-1,np.round(teachers_answer_ex3[i][j],r)),\"not equal\"\n",
    "        else:\n",
    "            assert np.array_equal(np.round(student_answer_ex3[i][j],r),np.round(teachers_answer_ex3[i][j],r)),\"not equal\"\n",
    "\n",
    "print(\"*********\")\n",
    "print(\"Passed dummy test cell\")\n",
    "print(\"Note : There are hidden test cells that run on a totally different but identical dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test_ex3",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 4** (2 point) : \n",
    "\n",
    "Transforming the samples onto the new space with top k eigenvectors, that have cumulative of variance explained percentage bigger or equal to a specific threshold.\n",
    "\n",
    "Step 1: From the eigen_list above, we can construct a $k×d$-dimensional eigenvector matrix $W$ (here $4×k$: based on the k most informative eigenpairs that have cumulative percentage of variance explained >= a specific threshold) and thereby reducing the initial 4-dimensional feature space into a k-dimensional feature subspace.\n",
    "\n",
    "Step 2: Next, we use the 4×k-dimensional matrix $W$ that we just computed to transform our samples onto the new subspace via the equation\n",
    "\n",
    "$$Y = X×W$$.\n",
    "\n",
    "where $X$ is a $n×d$-dimensional matrix representing the $n$ samples, and $Y$ is the transformed $n×k$-dimensional samples in the new subspace.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "![alt text](Ex4.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If variance_explained_threshold = 80, then W will be formed by Vec1.\n",
    "\n",
    "If variance_explained_threshold = 90, then W will be formed by Vec1 & Vec2.\n",
    "\n",
    "If variance_explained_threshold = 95, then W will be formed by Vec1, Vec2 & Vec3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def transformed_matrix(X, eigen_list, variance_explained_threshold=99.5):\n",
    "    \n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    \n",
    "Y = transformed_matrix(X,eigen_list,99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "dummy_ex4",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "Passed dummy test cell\n",
      "Note : There are hidden test cells that run on a totally different but identical dataset\n"
     ]
    }
   ],
   "source": [
    "## Dummy Test Cell 4\n",
    "\n",
    "student_answer_ex4 = transformed_matrix(X, teachers_answer_ex3, 99.5)\n",
    "# print(f'Your answer : \\n{student_answer_ex4}')\n",
    "\n",
    "student_answer_ex4_2 = transformed_matrix(X, teachers_answer_ex3, 99)\n",
    "# print(f'Your answer : \\n{student_answer_ex4_2}')\n",
    "\n",
    "assert (type(student_answer_ex4)==np.ndarray), \"Check the data type of your result\"\n",
    "assert (type(student_answer_ex4_2)==np.ndarray), \"Check the data type of your result\"\n",
    "\n",
    "teachers_answer_ex4 = np.load('../resource/asnlib/publicdata/teachers_answer_ex4.npy')\n",
    "# print(f'Our solution : \\n{teachers_answer_ex4}')\n",
    "teachers_answer_ex4_2 = np.load('../resource/asnlib/publicdata/teachers_answer_ex4_2.npy')\n",
    "# print(f'Our solution : \\n{teachers_answer_ex4_2}')\n",
    "\n",
    "assert np.array_equal(np.round(student_answer_ex4,r), np.round(teachers_answer_ex4,r)), \"Check the answer on threshold = 99.5\"\n",
    "assert np.array_equal(np.round(student_answer_ex4_2,r), np.round(teachers_answer_ex4_2,r)), \"Check the answer on threshold = 99\"\n",
    "\n",
    "print(\"*********\")\n",
    "print(\"Passed dummy test cell\")\n",
    "print(\"Note : There are hidden test cells that run on a totally different but identical dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "test_ex4",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex4 : HIDDEN TEST PASSED\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### How does our dataset look in the new subspace?\n",
    "\n",
    "Okay! Great job passing all the test cells. \n",
    "\n",
    "Let's visualize the transformed dataset in the new subspace (new dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plot_step(Y, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Finished!** You've reached the end of this problem. Don't forget to restart the kernel and run the entire notebook from top-to-bottom to make sure you did everything correctly. If that is working, try submitting this problem. (Recall that you must submit and pass the autograder to get credit for your work!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
