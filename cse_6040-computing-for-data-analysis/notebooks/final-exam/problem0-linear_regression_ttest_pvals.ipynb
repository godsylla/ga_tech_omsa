{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Problem 0: Linear Regression\n",
    "Recall the linear regression problem: given a data matrix, $X$, and responses $y$, we wish to determine the model parameters $\\theta^*$ that minimizes $\\|X \\theta - y\\|_2^2$. This problem is also known as the _linear least squares_ problem.\n",
    "\n",
    "In your classwork you learned to estimate the parameters $\\theta^*$. Here you will test the significance of those parameters and report the $R^2$ value for the model. We will continue to use the same functions to generate datasets for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Setup the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Data and computation\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Viz\n",
    "from IPython.display import display, Math\n",
    "from matplotlib.pyplot import figure, subplot, xlim, ylim\n",
    "from matplotlib.pyplot import scatter, axis, xlabel, ylabel, title, plot\n",
    "%matplotlib inline\n",
    "\n",
    "# Some functions we'll use later to display results\n",
    "def show_cond_fancy(x, name, opt=''):\n",
    "    \"\"\"Display a condition number in 'fancy' format (using LaTeX).\"\"\"\n",
    "    def sci_to_latex(x, fmt='{:.2e}'):\n",
    "        s_raw = fmt.format(x)\n",
    "        s, e = s_raw.split('e')\n",
    "        return s + r'\\times 10^{{{}}}'.format(int(e))\n",
    "    from IPython.display import Math\n",
    "    x_s = sci_to_latex(x)\n",
    "    display(Math(r'\\kappa({}){} \\approx {}'.format(name, opt, x_s)))\n",
    "    \n",
    "def show_2vecs_tibble(x, y, xname='x', yname='y', error=False):\n",
    "    \"\"\"Display two column vectors side-by-side in a tibble.\"\"\"\n",
    "    assert type(x) is np.ndarray and x.ndim >= 2 and x.shape[1] == 1\n",
    "    assert type(y) is np.ndarray and y.ndim >= 2 and y.shape[1] == 1\n",
    "    assert x.shape == y.shape\n",
    "    x_df = pd.DataFrame(x, columns=[xname])\n",
    "    y_df = pd.DataFrame(y, columns=[yname])\n",
    "    df = pd.concat([x_df, y_df], axis=1)\n",
    "    if error:\n",
    "        df['error'] = x - y\n",
    "    display(df)\n",
    "    \n",
    "# Display (X, y) problem as a tibble\n",
    "def make_data_tibble(X, y=None):\n",
    "    df = pd.DataFrame(X, columns=['x_{}'.format(i) for i in range(X.shape[1])])\n",
    "    if y is not None:\n",
    "        y_df = pd.DataFrame(y, columns=['y'])\n",
    "        df = pd.concat([y_df, df], axis=1)\n",
    "    return df\n",
    "    \n",
    "# From: https://stackoverflow.com/questions/17129290/numpy-2d-and-1d-array-to-latex-bmatrix\n",
    "def nparray_to_bmatrix(a):\n",
    "    \"\"\"Returns a LaTeX bmatrix\"\"\"\n",
    "    assert len(a.shape) <= 2, 'bmatrix can at most display two dimensions'\n",
    "    lines = str(a).replace('[', '').replace(']', '').splitlines()\n",
    "    rv = [r'\\begin{bmatrix}']\n",
    "    rv += ['  ' + ' & '.join(l.split()) + r'\\\\' for l in lines]\n",
    "    rv +=  [r'\\end{bmatrix}']\n",
    "    return '\\n'.join(rv)\n",
    "\n",
    "# Stash this function for later:\n",
    "SAVE_LSTSQ = np.linalg.lstsq # You may ignore this line, which some test cells will use\n",
    "\n",
    "def generate_model (n):\n",
    "    \"\"\"Returns a set of (random) n+1 linear model coefficients.\"\"\"\n",
    "    return np.random.rand (n+1, 1)\n",
    "\n",
    "def generate_data (m, theta, sigma=1.0/(2**0.5)):\n",
    "    \"\"\"\n",
    "    Generates 'm' noisy observations for a linear model whose\n",
    "    predictor (non-intercept) coefficients are given in 'theta'.\n",
    "    Decrease 'sigma' to decrease the amount of noise.\n",
    "    \"\"\"\n",
    "    assert (type (theta) is np.ndarray) and (theta.ndim == 2) and (theta.shape[1] == 1)\n",
    "    n = len (theta)\n",
    "    X = np.random.rand (m, n)\n",
    "    X[:, 0] = 1.0\n",
    "    y = X.dot (theta) + sigma*np.random.randn (m, 1)\n",
    "    return (X, y)\n",
    "\n",
    "# m is the number of data points and n is the number of predictors\n",
    "m = 100000\n",
    "k = 5\n",
    "np.random.seed(123)\n",
    "theta_true = generate_model(k)\n",
    "(X, y) = generate_data(m, theta_true, sigma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 0** (1 point): Estimate parameters\n",
    "\n",
    "Recall that $\\theta^*$ = $(X^TX)^{-1}X^Ty$\n",
    "\n",
    "Recall how parameters were estimated using linalg and then estimate the parameters. Define the function and set the variable <mark>**\"theta\"**</mark> to the estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_coeffs (X, y):\n",
    "    ###\n",
    "    Xt_X = X.T.dot(X)\n",
    "    Xt_X_inv = np.linalg.inv(Xt_X)\n",
    "    Xt_y = X.T.dot(y)\n",
    "    return Xt_X_inv.dot(Xt_y)\n",
    "    ###\n",
    "\n",
    "### Set theta here\n",
    "###\n",
    "theta = estimate_coeffs(X, y)\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise0",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# Test cell: `exercise0` (1 point)\n",
    "assert (np.round(theta_true - theta,1) == 0).all()\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.ravel().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 1** (2 points): Calculate $R^2$.  \n",
    "\n",
    "Also called the coefficient of determination, denoted R2 or r2 and pronounced \"R squared\", is the proportion of the variance in the dependent variable that is predictable from the independent variable(s). Refer to the [wiki page](https://en.wikipedia.org/wiki/Coefficient_of_determination) for more details. \n",
    "\n",
    "For the purpose of this question, you need to know the following terms.\n",
    "\n",
    "$SS_{tot} = \\sum\\limits_{i=1}^n (y_i - \\bar{y})^2$\n",
    "\n",
    "$SS_{res} = \\sum\\limits_{i=1}^n (y_i - f_i)^2$\n",
    "\n",
    "$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$\n",
    "\n",
    "**y** is the response and **f** is the predicted value\n",
    "\n",
    "Using the data provided above, define the three functions below and set the three values <mark>**sst, ssr, r_sq**</mark> using the respective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ss_total(y):\n",
    "    ###\n",
    "    y_mean = np.mean(y)\n",
    "    diffs = np.subtract(y, y_mean)\n",
    "    y_diff_sq = diffs ** 2\n",
    "    ###\n",
    "    return np.sum(y_diff_sq)\n",
    "\n",
    "def ss_res(X, y, theta):\n",
    "    ###\n",
    "    y_hat = X.dot(theta)\n",
    "    resids = np.subtract(y, y_hat)\n",
    "    res_sq = resids ** 2\n",
    "    return np.sum(res_sq)\n",
    "    ###\n",
    "\n",
    "def r_square(X, y, theta):\n",
    "    ###\n",
    "    ss_R = ss_res(X, y, theta)\n",
    "    ss_T = ss_total(y)\n",
    "    return 1 - (ss_R / ss_T)\n",
    "    ###\n",
    "\n",
    "### Set sst, ssr, r_sq here\n",
    "###\n",
    "sst = ss_total(y)\n",
    "ssr = ss_res(X, y, theta)\n",
    "r_sq = r_square(X, y, theta)\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise1",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# Test cell: `exercise1` (2 points)\n",
    "assert np.round(r_sq * ssr * sst,0) == 9459788\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 2** (3 points): Calculate standard errors for parameters. Recall that \n",
    "\n",
    "$var(\\hat{\\theta}) = \\hat{\\sigma}^2 (X^TX)^{-1}$\n",
    "\n",
    "$\\hat{\\sigma}^2 = \\frac{1}{m-(k+1)} \\sum\\limits_{i=1}^m\\hat\\epsilon_i^2$, where \n",
    "* m is the number of data points \n",
    "* k is the number of predictors and\n",
    "* epsilon is the difference between actual and predicted value (i.e. $\\hat\\epsilon_i=y_i - f_i$)\n",
    "\n",
    "$se(\\hat{\\theta}) =$ diagonal elements of $\\sqrt{var(\\hat{\\theta})}$  \n",
    "\n",
    "Hint: According to above formula, the standard errors are the diagonal elments of squared root of $var(\\hat{\\theta})$.\n",
    "\n",
    "Define the following function and return standard errors for parameters. Set the <mark>\"serr\"</mark> array with the standard errors. \n",
    "\n",
    "Note: return value should be an array of dimensions (k+1) X 1, where k is the number of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n",
      "[[0.00127037]\n",
      " [0.00109918]\n",
      " [0.0010978 ]\n",
      " [0.00109996]\n",
      " [0.0011002 ]\n",
      " [0.00109979]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in sqrt\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "def std_error(X, y, theta):\n",
    "     \n",
    "    ###\n",
    "    m = len(X)        # Number of data points\n",
    "    \n",
    "    constant = (1 / (m - (k + 1)))\n",
    "    \n",
    "    ss_residuals = ss_res(X, y, theta)\n",
    "    \n",
    "    sigma_hat_sq = constant * ss_residuals\n",
    "    variance = sigma_hat_sq * np.linalg.inv(X.T.dot(X))\n",
    "    \n",
    "    return np.diag(np.sqrt(variance)).reshape(-1, 1)\n",
    "    ###\n",
    "\n",
    "### Set \"serr\" here\n",
    "###\n",
    "serr = std_error(X, y, theta)\n",
    "print(serr.shape)\n",
    "print(serr)\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise2",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# Test cell: `exercise2` (3 points)\n",
    "assert serr.shape[0] == 6\n",
    "assert serr.shape[1] == 1\n",
    "assert np.round(np.sum(serr),4) == 0.0068\n",
    "assert (np.round(serr[1] + serr[3],5) == 0.0022)\n",
    "assert (np.round(serr[2] + serr[4],5) == 0.0022)\n",
    "assert (np.round(serr[5] + serr[0],5) == 0.00237)\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 3** (2 points): Calculate  t-statisic and the corresponding p-values\n",
    "\n",
    "$t_i = \\frac{\\hat{\\theta_i}}{se(\\hat{\\theta_i})}$\n",
    "\n",
    "$p-value = 2 * (1- P(T\\leq|t_i|))$ . More details [here](https://en.wikipedia.org/wiki/P-value).\n",
    "\n",
    "For calculating this you will need, $df ($degrees $of $freedom) = m - (k+1), where m is the number of observations and k is the number of predictors, $t_i$ is the t-statistic you calculated above.\n",
    "* Set \"df\" to the appropriate number. \n",
    "* Define the following functions\n",
    "* Use scipy stats library (stats.t.sf) and use the t-statistic (computed) to obtain the p_values. \n",
    "* Set <mark>\"tstat\"</mark> array with the t-statistic and <mark>\"pvals\"</mark> array with the p-values of the corresponding parameters. Array shape should be the same shape as that of <mark>\"theta\"</mark>\n",
    "\n",
    "Note: For the functions, return valuse should be an array of shape (k+1) X 1, where k is the number of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69508066],\n",
       "       [0.28673186],\n",
       "       [0.22835872],\n",
       "       [0.55018565],\n",
       "       [0.7198887 ],\n",
       "       [0.42433513]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00127037],\n",
       "       [0.00109918],\n",
       "       [0.0010978 ],\n",
       "       [0.00109996],\n",
       "       [0.0011002 ],\n",
       "       [0.00109979]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([547.14760379])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[0] / serr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "5\n",
      "99994\n",
      "[[547.14760379]\n",
      " [260.86093254]\n",
      " [208.01451981]\n",
      " [500.18517903]\n",
      " [654.32804571]\n",
      " [385.83411449]]\n",
      "2556.3703953675326\n",
      "(6, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "2556.3703953675326\n"
     ]
    }
   ],
   "source": [
    "def t_statistic(theta, serr):\n",
    "    ###\n",
    "    return np.array([t / s for t, s in zip(theta, serr)])\n",
    "    ###\n",
    "\n",
    "def p_values(tstat, df):\n",
    "    ###\n",
    "    p_vals = np.zeros(tstat.shape)\n",
    "    \n",
    "    for i, tt in enumerate(tstat):\n",
    "        t = abs(tt)\n",
    "        p_vals[i] = stats.t.sf(np.abs(t), df)*2 \n",
    "        \n",
    "    return p_vals\n",
    "    ###\n",
    "\n",
    "# set df, tstat and pvals here\n",
    "###\n",
    "m = X.shape[0]\n",
    "print(m)\n",
    "print(k)\n",
    "\n",
    "df = m - (k + 1)\n",
    "print(df)\n",
    "\n",
    "tstat = t_statistic(theta, serr)\n",
    "print(tstat)\n",
    "print(np.sum(tstat))\n",
    "\n",
    "pvals = p_values(tstat, df)\n",
    "print(pvals.shape)\n",
    "print(pvals)\n",
    "print(np.sum(tstat) + np.sum(pvals))\n",
    "assert round(np.sum(tstat) + np.sum(pvals), 5) == 2556.3704 \n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise3",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# Test cell: `exercise3` (2 points)\n",
    "assert tstat.shape[0] == 6\n",
    "assert tstat.shape[1] == 1\n",
    "assert pvals.shape[0] == 6\n",
    "assert pvals.shape[1] == 1\n",
    "assert np.round(np.sum(serr),4) == 0.0068\n",
    "assert (np.round(np.sum(tstat),4) + np.sum(pvals) == 2556.3704)\n",
    "assert np.round(tstat[0]+tstat[1], 5) == 808.00854\n",
    "assert np.round(tstat[2]+tstat[3], 5) ==  708.1997\n",
    "assert np.round(tstat[4]+tstat[5], 5) == 1040.16216\n",
    "\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 4** (2 points): Find the confidence interval of regression co-efficients. \n",
    "\n",
    "For a given $\\alpha$, confidence interval states that all possible sample estimates (for that parameter) will be in this particular interval, 100 * (1-$\\alpha$)% of the time. Let's proceed to calculate the confidence intervals.\n",
    "\n",
    "$Confidence\\ Interval\\ of\\ \\theta = \\hat{\\theta_i}\\pm t_{\\alpha/2, m-(k+1)} * se(\\hat{\\theta_i})$ \n",
    "\n",
    "We have already calculated theta and serr values above. Degrees of freedom is same as that mentioned in exercise 3. Use them to estimate the confidence intervals for parameters at <mark>$\\alpha$ = 0.05</mark>. Use Scipy function (\"stats.t.ppf\") to get the t-value.\n",
    "\n",
    "Return the array <mark>cinterval</mark>. Rows represent parameters and Columns represent the low-interval and high-intervals computed for that particular parameter.\n",
    "\n",
    "Note: return value should be 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2, 1)\n",
      "5.809161447038596\n"
     ]
    }
   ],
   "source": [
    "def conf_interval(theta, serr, df, alpha):\n",
    "    ###\n",
    "    conf_interval = np.zeros(shape=theta.shape)\n",
    "    \n",
    "#     lows_highs = []\n",
    "#     for i in range(len(theta)):\n",
    "    t = stats.t.ppf(alpha/2, df)\n",
    "    high = theta + (t * serr)\n",
    "    low = theta - (t * serr)\n",
    "\n",
    "    return np.array(list(zip(high, low)))\n",
    "    ###\n",
    "\n",
    "### Set cinterval\n",
    "###\n",
    "cinterval = conf_interval(theta, serr, df, 0.05)\n",
    "print(cinterval.shape)\n",
    "print(np.sum(cinterval))\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "exercise4",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# Test cell: `exercise4` (2 points)\n",
    "step1 = np.round(stats.t.ppf(1-np.abs(0.05/2), df)*2*serr,7)\n",
    "step2 = np.round((cinterval[:,1] - cinterval[:,0]).reshape(6,1),7)\n",
    "\n",
    "assert np.round(np.sum(cinterval),5) == 5.80916\n",
    "assert (step1 == step2).all()\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Great!** You have reached the end of the problem. Submit and proceed to the next problem. Don't forget to restart the kernel and run the entire notebook from top-to-bottom to make sure you did everything correctly. If that is working, try submitting this problem. (RecalL that you *must* submit and pass the autograder to get credit for your work!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Optional: Fitting X and y using StatsModel (Verification)\n",
    "If you are interested then you can see how close your values are to the values computed by the standard library. We print r_sq, serr, pvals, tstat and cinterval values to check against the values output by the standard library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.903</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.903</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.869e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 28 Apr 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:23:57</td>     <th>  Log-Likelihood:    </th>  <td>  88064.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>100000</td>      <th>  AIC:               </th> <td>-1.761e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 99994</td>      <th>  BIC:               </th> <td>-1.761e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.6951</td> <td>    0.001</td> <td>  547.148</td> <td> 0.000</td> <td>    0.693</td> <td>    0.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.2867</td> <td>    0.001</td> <td>  260.861</td> <td> 0.000</td> <td>    0.285</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2284</td> <td>    0.001</td> <td>  208.015</td> <td> 0.000</td> <td>    0.226</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.5502</td> <td>    0.001</td> <td>  500.185</td> <td> 0.000</td> <td>    0.548</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.7199</td> <td>    0.001</td> <td>  654.328</td> <td> 0.000</td> <td>    0.718</td> <td>    0.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.4243</td> <td>    0.001</td> <td>  385.834</td> <td> 0.000</td> <td>    0.422</td> <td>    0.426</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.886</td> <th>  Durbin-Watson:     </th> <td>   2.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.389</td> <th>  Jarque-Bera (JB):  </th> <td>   1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.009</td> <th>  Prob(JB):          </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.010</td> <th>  Cond. No.          </th> <td>    7.97</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.903\n",
       "Model:                            OLS   Adj. R-squared:                  0.903\n",
       "Method:                 Least Squares   F-statistic:                 1.869e+05\n",
       "Date:                Sun, 28 Apr 2019   Prob (F-statistic):               0.00\n",
       "Time:                        16:23:57   Log-Likelihood:                 88064.\n",
       "No. Observations:              100000   AIC:                        -1.761e+05\n",
       "Df Residuals:                   99994   BIC:                        -1.761e+05\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.6951      0.001    547.148      0.000       0.693       0.698\n",
       "x1             0.2867      0.001    260.861      0.000       0.285       0.289\n",
       "x2             0.2284      0.001    208.015      0.000       0.226       0.231\n",
       "x3             0.5502      0.001    500.185      0.000       0.548       0.552\n",
       "x4             0.7199      0.001    654.328      0.000       0.718       0.722\n",
       "x5             0.4243      0.001    385.834      0.000       0.422       0.426\n",
       "==============================================================================\n",
       "Omnibus:                        1.886   Durbin-Watson:                   2.013\n",
       "Prob(Omnibus):                  0.389   Jarque-Bera (JB):                1.875\n",
       "Skew:                           0.009   Prob(JB):                        0.392\n",
       "Kurtosis:                       3.010   Cond. No.                         7.97\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Printing summary stats r-sq, serr, tstat, pvalues and cinterval calculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Results\n",
      "R-Squared:  0.903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P &gt; |t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.001</td>\n",
       "      <td>547.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.001</td>\n",
       "      <td>260.861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.001</td>\n",
       "      <td>208.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500.185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>654.328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4243</td>\n",
       "      <td>0.001</td>\n",
       "      <td>385.834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coef  std err        t  P > |t|  [0.025  0.975]\n",
       "0  0.6951    0.001  547.148      0.0   0.693   0.698\n",
       "1  0.2867    0.001  260.861      0.0   0.285   0.289\n",
       "2  0.2284    0.001  208.015      0.0   0.226   0.231\n",
       "3  0.5502    0.001  500.185      0.0   0.548   0.552\n",
       "4  0.7199    0.001  654.328      0.0   0.718   0.722\n",
       "5  0.4243    0.001  385.834      0.0   0.422   0.426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Regression Results\")\n",
    "print(\"R-Squared: \", np.round(r_sq,3))\n",
    "final_df = pd.DataFrame(np.round(theta,4))\n",
    "\n",
    "final_df.columns = ['coef']\n",
    "final_df['std err'] = pd.DataFrame(np.round(serr,3))\n",
    "final_df['t'] = pd.DataFrame(np.round(tstat,3))\n",
    "final_df['P > |t|'] = pd.DataFrame(np.round(pvals,3))\n",
    "final_df['[0.025'] = pd.DataFrame(np.round(cinterval[:,0], 3))\n",
    "final_df['0.975]'] = pd.DataFrame(np.round(cinterval[:,1], 3))\n",
    "\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Fin!** You've reached the end of this problem. Don't forget to restart the kernel and run the entire notebook from top-to-bottom to make sure you did everything correctly. If that is working, try submitting this problem. (RecalL that you *must* submit and pass the autograder to get credit for your work!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
