{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81740ad10bcffdd8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1 of 2: Processing an HTML file\n",
    "\n",
    "One of the richest sources of information is [the Web](http://www.computerhistory.org/revolution/networking/19/314)! In this notebook, we ask you to use string processing and regular expressions to mine a web page, which is stored in HTML format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e1821fbeefa0e2c2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**The data: Yelp! reviews.** The data you will work with is a snapshot of a recent search on the [Yelp! site](https://yelp.com) for the best fried chicken restaurants in Atlanta. That snapshot is hosted here: https://cse6040.gatech.edu/datasets/yelp-example\n",
    "\n",
    "If you go ahead and open that site, you'll see that it contains a ranked list of places:\n",
    "\n",
    "![Top 10 Fried Chicken Spots in ATL as of September 12, 2017](https://cse6040.gatech.edu/datasets/yelp-example/ranked-list-snapshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe765896f1d25066",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Your task.** In this part of this assignment, we'd like you to write some code to extract this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-95c9a0ef4d1838e1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Getting the data\n",
    "\n",
    "First things first: you need an HTML file. The following Python code will download a particular web page that we've prepared for this exercise and store it locally in a file.\n",
    "\n",
    "> If the file exists, this command will not overwrite it. By not doing so, we can reduce accesses to the server that hosts the file. Also, if an error occurs during the download, this cell may report that the downloaded file is corrupt; in that case, you should try re-running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af1ae6df64a1fd40",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'yelp.htm' is ready!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "if os.path.exists('.voc'):\n",
    "    data_url = 'https://cse6040.gatech.edu/datasets/yelp-example/yelp.htm'\n",
    "else:\n",
    "    data_url = 'https://github.com/cse6040/labs-fa17/raw/master/datasets/yelp.htm'\n",
    "\n",
    "if not os.path.exists('yelp.htm'):\n",
    "    print(\"Downloading: {} ...\".format(data_url))\n",
    "    r = requests.get(data_url)\n",
    "    with open('yelp.htm', 'w', encoding=r.encoding) as f:\n",
    "        f.write(r.text)\n",
    "\n",
    "with open('yelp.htm', 'r', encoding='utf-8') as f:\n",
    "    yelp_html = f.read().encode(encoding='utf-8')\n",
    "    checksum = hashlib.md5(yelp_html).hexdigest()\n",
    "    assert checksum == \"4a74a0ee9cefee773e76a22a52d45a8e\", \"Downloaded file has incorrect checksum!\"\n",
    "    \n",
    "print(\"'yelp.htm' is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-afee39f0b7aee426",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Viewing the raw HTML in your web browser.** The file you just downloaded is the raw HTML version of the data described previously. Before moving on, you should go back to that site and use your web browser to view the HTML source for the web page. Do that now to get an idea of what is in that file.\n",
    "\n",
    "> If you don't know how to view the page source in your browser, try the instructions on [this site](http://www.wikihow.com/View-Source-Code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-993d633285178cf8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Reading the HTML file into a Python string.** Let's also open the file in Python and read its contents into a string named, `yelp_html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** type(yelp_html) == <class 'str'> ***\n",
      "*** Contents (first 1000 characters) ***\n",
      "<!DOCTYPE html>\n",
      "<!-- saved from url=(0079)https://www.yelp.com/search?find_desc=fried+chicken&find_loc=Atlanta%2C+GA&ns=1 -->\n",
      "<html xmlns:fb=\"http://www.facebook.com/2008/fbml\" class=\"js gr__yelp_com\" lang=\"en\"><!--<![endif]--><head data-component-bound=\"true\"><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"><link type=\"text/css\" rel=\"stylesheet\" href=\"./Best Fried chicken in Atlanta, GA - Yelp_files/css\"><style type=\"text/css\">.gm-style .gm-style-cc span,.gm-style .gm-style-cc a,.gm-style .gm-style-mtc div{font-size:10px}\n",
      "</style><style type=\"text/css\">@media print {  .gm-style .gmnoprint, .gmnoprint {    display:none  }}@media screen {  .gm-style .gmnoscreen, .gmnoscreen {    display:none  }}</style><style type=\"text/css\">.gm-style-pbc{transition:opacity ease-in-out;background-color:rgba(0,0,0,0.45);text-align:center}.gm-style-pbt{font-size:22px;color:white;font-family:Roboto,Arial,sans-serif;position:relative;margin:0;top:50%;-webkit-transform:translateY(-50%);-ms-transform:translateY(-50%);transform:translateY(-50%)}\n",
      "</style><script src=\"./Best Fried chicken in Atlanta, GA - Yelp_files/rules-p-M4yfUTCPeS3vn.js\" style=\"\"></script><script src=\"./Best Fried chicken in Atlanta, GA - Yelp_files/segments.json\" async=\"\" type=\"text/javascript\"></script>\n",
      "\n",
      "\n",
      "    <script src=\"./Best Fried chicken in Atlanta, GA - Yelp_files/102029836881428\" async=\"\"></script><script async=\"\" src=\"./Best Fried chicken in Atlanta, GA - Yelp_files/fbevents.js\"></script><script async=\"\" src=\"./Best Fried chicken in Atlanta, GA - Yelp_files/async-ads.js\"></script><script async=\"\" src=\"./Best Fried chicken in Atlanta, GA - Yelp_files/analytics.js\"></script><script>            window.yPageStart = new Date().getTime();\n",
      "</script>\n",
      "\n",
      "    <script>            var initialVisibilityState = document.webkitVisibilityState;\n",
      "\n",
      "                yPerfTimings = [];\n",
      "\n",
      "                ySitRepParams = {\"b3Sampled\": null, \"edgeStartTime\": 1505255565245572, \"site\": \"main\", \"uniqueRequestID\": \"f2da9c903fcf056d\", \"isLoggedIn\": false, \"clientIP\": \"76.20.254.8\", \"servlet\": \"search\", \"zipkinTraceID\": \"f2da9c903fcf056d\", \"datacenter\": \"us-east-1\", \"cfRayID\": null, \"serverStartTime\": 1505255565272, \"action\": \"search_html\", \"yuv_record\": \"WZD9cdROxjIbbAxurlTGZAvM4H4Tb3yahub1Mx34vjgM5OvLvcHrctoizFPNkLM3nOyCpaGokHa5xijxqgBR0L6aE_fwB1EN\"};\n",
      "                window.ySitRepParams['initialVisibilityState'] = initialVisibilityState;\n",
      "                window.ySitRepParams['seoCohorts'] = null;\n",
      "\n",
      "\n",
      "            (function(H){H.className=H.className.replace(/\\bno-js\\b/,'js');})(document.documentElement);\n",
      "</script>\n",
      "\n",
      "            <script>            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n",
      "</script>\n",
      "\n",
      "\n",
      "            <script>\n",
      "            (function() {\n",
      "                var main = null;\n",
      "\n",
      "                var d=this;function h(a,b){var c=a.split(\".\"),e=d;c[0]in e||!e.execScript||e.execScript(\"var \"+c[0]);for(var f;c.length&&(f=c.shift());)c.length||void 0===b?e[f]?e=e[f]:e=e[f]={}:e[f]=b};function k(a,b){for(var c=0;c<a.length;c++)if(a[c]===b)return c;return-1};function l(a){var b=$(window);function c(a,b){return 0<=a&&a<=b}function e(a,b){return 0>=a.left&&a.right>=b.width()||0>=a.top&&a.bottom>=b.height()}function f(a,b){return c(a.left,b.width())&&!(a.top>=b.height()||0>=a.bottom)}function g(a,b){return c(a.right,b.width())&&!(a.top>=b.height()||0>=a.bottom)}function n(a,b){return c(a.bottom,b.height())&&!(a.left>=b.width()||0>=a.right)}a=a.getBoundingClientRect();return function(a,b){return c(a.top,b.height())&&!(a.left>=b.width()||0>=a.right)}(a,b)||\n",
      "f(a,b)||g(a,b)||n(a,b)||e(a,b)};function m(){this.a=[];this.hasOwnProperty(\"value_\")&&delete this.value_}m.prototype.J=function(a){var b=this;this.hasOwnProperty(\"value_\")?setTimeout(function(){a.call(this,b.value_)},0):this.a.push(a)};m.prototype.getInstance=m.prototype.J;function q(a){window.ga||(window.ga=function(){});this.U=(new Date).getTime();this.reload(a)}var r;h(\"yelp_google_analytics.google_analytics\",q);var u=new m,v=[\"global\",\"m\",\"www\",\"biz\",\"webview\"];function w(a,b,c){if(c)for(var e in c[b])c[b].hasOwnProperty(e)&&(a.g[b][e]=c[b][e][0])}q.prototype.F=function(a,b){window.ga(x(\"set\",b),\"page\",a)};q.prototype.setPage=q.prototype.F;q.prototype.K=function(){return window.ga.getAll()};q.prototype.getTrackers=q.prototype.K;\n",
      "q.prototype.s=function(a){for(var b in this.a)this.a.hasOwnProperty(b)&&y(this,String(b),a)};q.prototype.firePageviews=q.prototype.s;q.prototype.H=function(a){for(var b in this.a)this.a.hasOwnProperty(b)&&(\"global\"!==b||this.l)&&y(this,String(b),a)};q.prototype.firePageviewsWithGlobalTrackerSampled=q.prototype.H;function y(a,b,c){c&&a.F(c,b);window.ga(x(\"send\",b),\"pageview\")}\n",
      "function x(a,b){if(0<=k(v,b))return[b,a].join(\".\");throw Error(\"google analytics attempted to set \"+a+\" to an unrecognized tracker alias: \"+b);}q.prototype.N=function(a,b,c){a=this.g[c][a];\"undefined\"!=typeof a&&null!==b&&(this.b[c][\"dimension\"+a]=b.toString())};q.prototype.setDimensionOneEvent=q.prototype.N;q.prototype.j=function(a,b,c){a=this.g[c][a];\"undefined\"!=typeof a&&null!==b&&window.ga(x(\"set\",c),\"dimension\"+a,b.toString())};q.prototype.setDimension=q.prototype.j;\n",
      "q.prototype.O=function(a,b){for(var c in a)a.hasOwnProperty(c)&&this.j(c,a[c],b)};q.prototype.setDimensions=q.prototype.O;q.prototype.D=function(a,b,c){window.ga(x(\"set\",c),\"metric\"+a,b)};q.prototype.setMetric=q.prototype.D;q.prototype.P=function(a,b,c){this.c[c][a]=b};q.prototype.setMetricOneEvent=q.prototype.P;\n",
      "q.prototype.i=function(a,b,c,e,f){for(var g in this.a)if(this.a.hasOwnProperty(g)){var n={hitType:\"event\",eventCategory:a,eventAction:b,eventLabel:c,eventValue:e,hitCallback:f,nonInteraction:!0},p;for(p in this.b[g])this.b[g].hasOwnProperty(p)&&(n[p]=this.b[g][p]);for(var t in this.c[g])this.c[g].hasOwnProperty(t)&&(n[\"metric\"+t]=this.c[g][t]);this.b[g]={};this.c[g]={};\"global\"!==g&&window.ga(x(\"send\",String(g)),n)}};q.prototype.trackEvent=q.prototype.i;\n",
      "q.prototype.T=function(a,b,c,e){a={hitType:\"timing\",timingCategory:a,timingVar:b,timingValue:c,timingLabel:e};for(var f in this.a)this.a.hasOwnProperty(f)&&(b=a,window.ga(x(\"send\",String(f)),b))};q.prototype.trackTiming=q.prototype.T;q.prototype.G=function(a,b,c,e,f){this.l&&this.i(a+\" / 10\",b,c,e,f)};q.prototype.trackEventHighVolume=q.prototype.G;q.prototype.M=function(a,b){return b in this.g[a]};q.prototype.isExperimentSet=q.prototype.M;\n",
      "q.prototype.v=function(){var a=this;$(window).on(\"beforeunload\",function(){a.j(\"viewport_tracking\",a.m.join(\",\"),\"www\");var b=Math.round(((new Date).getTime()-a.U)/1E3),c=\"240+\";0>=b?c=\"5\":30>=b?c=(5*Math.ceil(b/5)).toString():120>=b?c=(15*Math.ceil(b/15)).toString():240>=b&&(c=(30*Math.ceil(b/30)).toString());a.G(\"time on page\",\"unload\",c,b)})};q.prototype.initTimeOnPageEvent=q.prototype.v;q.prototype.u=function(){var a=this;setTimeout(function(){a.i(\"dwell time\",\"dwell\",\"30 seconds\")},3E4)};\n",
      "q.prototype.initDwellTimeEvent=q.prototype.u;q.prototype.o=function(){for(var a=document.getElementsByClassName(\"js-ga-widget\"),b=0;b<a.length;b++){var c=a[b],e=c.getAttribute(\"data-ga-widget-name\")||\"Unnamed Widget\";0>k(this.m,e)&&l(c)&&this.m.push(e)}};q.prototype.addNewlyVisibleWidgets_=q.prototype.o;q.prototype.L=function(){if(Function.prototype.bind&&document.g ...\n"
     ]
    }
   ],
   "source": [
    "with open('yelp.htm', 'r', encoding='utf-8') as yelp_file:\n",
    "    yelp_html = yelp_file.read()\n",
    "    \n",
    "# Print first few hundred characters of this string:\n",
    "print(\"*** type(yelp_html) == {} ***\".format(type(yelp_html)))\n",
    "n = 1000\n",
    "print(\"*** Contents (first {} characters) ***\\n{} ...\".format(n, yelp_html[:7500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02895e5c5a7d18be",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Oy, what a mess! It will be great to have some code read and process the information contained within this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6481539b4054dbde",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Exercise (5 points): Extracting the ranking\n",
    "\n",
    "Write some Python code to create a variable named `rankings`, which is a list of dictionaries set up as follows:\n",
    "\n",
    "* `rankings[i]` is a dictionary corresponding to the restaurant whose rank is `i+1`. For example, from the screenshot above, `rankings[0]` should be a dictionary with information about Gus's World Famous Fried Chicken.\n",
    "* Each dictionary, `rankings[i]`, should have these keys:\n",
    "    * `rankings[i]['name']`: The name of the restaurant, a string.\n",
    "    * `rankings[i]['stars']`: The star rating, as a string, e.g., `'4.5'`, `'4.0'`\n",
    "    * `rankings[i]['numrevs']`: The number of reviews, as an **integer.**\n",
    "    * `rankings[i]['price']`: The price range, as dollar signs, e.g., `'$'`, `'$$'`, `'$$$'`, or `'$$$$'`.\n",
    "    \n",
    "Of course, since the current topic is regular expressions, you might try to apply them (possibly combined with other string manipulation methods) find the particular patterns that yield the desired information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "rankings",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Best Fried chicken in Atlanta, GA - Yelp</title>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "soup = BeautifulSoup(yelp_html, 'html.parser')\n",
    "soup.title\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "rankings",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'head'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<p>\n",
       "                First, try refreshing the page and clicking Current Location again. Make sure you click <b>Allow</b> or <b>Grant Permissions</b> if your browser asks for your location. If your browser doesn't ask you, try these steps:\n",
       "            </p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.yelp.com/search?find_desc=fried+chicken&amp;find_loc=Atlanta%2C+GA&amp;ns=1#header_find_form\" rel=\"nofollow\">\n",
       "                        Skip to Search Form\n",
       "                    </a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "display(soup.title.name)\n",
    "display(soup.title.parent.name)\n",
    "display(soup.p)\n",
    "display(soup.a)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup functions\n",
    "def extract_business_names (read_html):\n",
    "    # To find the business names on the page\n",
    "    soup = BeautifulSoup(read_html, 'html.parser')\n",
    "    \n",
    "    raw_biznames = list(soup.find_all(\"a\", attrs={\"class\":\"biz-name js-analytics-click\"}))\n",
    "    \n",
    "    # Convert the html format into strings\n",
    "    all_biznames = [str(bizname) for bizname in raw_biznames]\n",
    "    \n",
    "    # Get indices for the start and end of the business names using regex\n",
    "    beginnings = [re.search(r'><span>', bizname) for bizname in all_biznames]\n",
    "    endings = [re.search(r'</span></a>', bizname) for bizname in all_biznames]\n",
    "    # Get the end of the beginnings, and the beginning of the ends to find the indices where the bizname sits \n",
    "    biz_indices = list(zip([beg.span()[1] for beg in beginnings], [end.span()[0] for end in endings]))\n",
    "    \n",
    "    biznames = [name[biz_indices[i][0]: biz_indices[i][1]] for i, name in enumerate(all_biznames)]\n",
    "    return biznames\n",
    "\n",
    "def extract_avg_star_ratings (read_html):\n",
    "    # Instantiate beautiful soup\n",
    "    soup = BeautifulSoup(read_html, 'html.parser')\n",
    "    \n",
    "    # To find the stars for each of the listed business names (including ads)\n",
    "    raw_stars = soup.find_all('div', attrs={'class':'i-stars'})\n",
    "    str_stars = [str(star) for star in raw_stars]\n",
    "    \n",
    "    # Use regex to find the actual star ratings & isolate those\n",
    "    beginnings = [re.search(r'title=\"', stars) for stars in str_stars]\n",
    "    endings = [re.search(r' star rating', stars) for stars in str_stars]\n",
    "    \n",
    "    star_indices = list(zip([beg.span()[1] for beg in beginnings], [end.span()[0] for end in endings]))\n",
    "    stars = [star[star_indices[i][0]: star_indices[i][1]] for i, star in enumerate(str_stars)]\n",
    "    \n",
    "    return stars\n",
    "\n",
    "def extract_review_counts (read_html):\n",
    "    # Instantiate BeautifulSoup\n",
    "    soup = BeautifulSoup(read_html, 'html.parser')\n",
    "    \n",
    "    # find the review counts\n",
    "    all_counts = soup.find_all('span', attrs={'class':'review-count'})\n",
    "    str_counts = [str(count) for count in all_counts]\n",
    "    \n",
    "    # match the exact review count (only want the integer)\n",
    "    digits = [re.search(r'\\d+', str_counts[i]) for i in range(len(str_counts))]\n",
    "    nums = [int(digit.group()) for digit in digits]\n",
    "    \n",
    "    return nums\n",
    "\n",
    "def extract_price_ranges (read_html):\n",
    "    soup = BeautifulSoup(read_html, 'html.parser')\n",
    "    \n",
    "    # Find all the price ranges\n",
    "    all_pr_ranges = soup.find_all(\"span\", attrs={'class':'business-attribute price-range'})\n",
    "    str_pr_ranges = [str(prices) for prices in all_pr_ranges]\n",
    "    \n",
    "    # Find the beginning indices and the ending indices\n",
    "    begs = [re.search(r'price-range\">', ranges) for ranges in str_pr_ranges]\n",
    "    ends = [re.search(r'</span>', ranges) for ranges in str_pr_ranges]\n",
    "    # Zip the indices together\n",
    "    indices = list(zip([beg.span()[1] for beg in begs], [end.span()[0] for end in ends]))\n",
    "    \n",
    "    # Get the price ranges from the string price ranges\n",
    "    prices = [price[indices[i][0]: indices[i][1]] for i, price in enumerate(str_pr_ranges)]\n",
    "    \n",
    "    return prices\n",
    "\n",
    "def get_only_results_not_ads (read_html):\n",
    "    '''\n",
    "    returns only the indices of the advertisements, so as to know which to exclude from the above functions\n",
    "    '''\n",
    "    soup = BeautifulSoup(read_html, 'html.parser')\n",
    "    \n",
    "    all_biznames = soup.find_all(\"a\", attrs={\"class\":\"biz-name js-analytics-click\"})\n",
    "    str_biznames = [str(bizname) for bizname in all_biznames]\n",
    "    \n",
    "    ad_indices = []\n",
    "    for i, name in enumerate(str_biznames):\n",
    "        if 'ad_business_id' in name:\n",
    "            ad_indices.append(i) \n",
    "    \n",
    "    return ad_indices\n",
    "\n",
    "def remove_ads (idx_to_remove: list, result_attr:list) -> list:\n",
    "    \n",
    "    no_ads = []\n",
    "    for i, result in enumerate(result_attr):\n",
    "        if i not in idx_to_remove:\n",
    "            no_ads.append(result)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return no_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': ['Gus’s World Famous Fried Chicken',\n",
      "          'South City Kitchen - Midtown',\n",
      "          'Mary Mac’s Tea Room',\n",
      "          'Busy Bee Cafe',\n",
      "          'Richards’ Southern Fried',\n",
      "          'Greens &amp; Gravy',\n",
      "          'Colonnade Restaurant',\n",
      "          'South City Kitchen Buckhead',\n",
      "          'Poor Calvin’s',\n",
      "          'Rock’s Chicken &amp; Fries'],\n",
      " 'numrevs': [549, 1777, 2241, 481, 108, 93, 350, 248, 1558, 67],\n",
      " 'price': ['$$', '$$', '$$', '$$', '$$', '$$', '$$', '$$', '$$', '$'],\n",
      " 'stars': ['4.0',\n",
      "           '4.5',\n",
      "           '4.0',\n",
      "           '4.0',\n",
      "           '4.0',\n",
      "           '3.5',\n",
      "           '4.0',\n",
      "           '4.5',\n",
      "           '4.5',\n",
      "           '4.0']}\n"
     ]
    }
   ],
   "source": [
    "biznames = extract_business_names(yelp_html)\n",
    "star_ratings = extract_avg_star_ratings(yelp_html)\n",
    "price_ranges = extract_price_ranges(yelp_html)\n",
    "review_counts = extract_review_counts(yelp_html)\n",
    "\n",
    "ad_indices = get_only_results_not_ads(yelp_html)\n",
    "\n",
    "parent_d = dict(zip(['name', 'numrevs', 'price', 'stars'], [\n",
    "    remove_ads(ad_indices, biznames),\n",
    "    remove_ads(ad_indices, review_counts),\n",
    "    remove_ads(ad_indices, price_ranges),\n",
    "    remove_ads(ad_indices, star_ratings),\n",
    "]))\n",
    "\n",
    "pprint(parent_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Gus’s World Famous Fried Chicken',\n",
       "  'numrevs': 549,\n",
       "  'price': '$$',\n",
       "  'stars': '4.0'},\n",
       " {'name': 'South City Kitchen - Midtown',\n",
       "  'numrevs': 1777,\n",
       "  'price': '$$',\n",
       "  'stars': '4.5'},\n",
       " {'name': 'Mary Mac’s Tea Room',\n",
       "  'numrevs': 2241,\n",
       "  'price': '$$',\n",
       "  'stars': '4.0'},\n",
       " {'name': 'Busy Bee Cafe', 'numrevs': 481, 'price': '$$', 'stars': '4.0'},\n",
       " {'name': 'Richards’ Southern Fried',\n",
       "  'numrevs': 108,\n",
       "  'price': '$$',\n",
       "  'stars': '4.0'},\n",
       " {'name': 'Greens &amp; Gravy', 'numrevs': 93, 'price': '$$', 'stars': '3.5'},\n",
       " {'name': 'Colonnade Restaurant',\n",
       "  'numrevs': 350,\n",
       "  'price': '$$',\n",
       "  'stars': '4.0'},\n",
       " {'name': 'South City Kitchen Buckhead',\n",
       "  'numrevs': 248,\n",
       "  'price': '$$',\n",
       "  'stars': '4.5'},\n",
       " {'name': 'Poor Calvin’s', 'numrevs': 1558, 'price': '$$', 'stars': '4.5'},\n",
       " {'name': 'Rock’s Chicken &amp; Fries',\n",
       "  'numrevs': 67,\n",
       "  'price': '$',\n",
       "  'stars': '4.0'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create child dictionaries for each business result in the yelp search\n",
    "# append each child dictionary to a list called `rankings`\n",
    "\n",
    "rankings = []\n",
    "\n",
    "for i in range(10):\n",
    "    child_d = {}\n",
    "    for k, v in parent_d.items():\n",
    "        child_d[k] = v[i]\n",
    "        \n",
    "    rankings.append(child_d)\n",
    "    \n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "rankings_test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rankings ===\n",
      "1. Gus’s World Famous Fried Chicken ($$): 4.0 stars based on 549 reviews\n",
      "2. South City Kitchen - Midtown ($$): 4.5 stars based on 1777 reviews\n",
      "3. Mary Mac’s Tea Room ($$): 4.0 stars based on 2241 reviews\n",
      "4. Busy Bee Cafe ($$): 4.0 stars based on 481 reviews\n",
      "5. Richards’ Southern Fried ($$): 4.0 stars based on 108 reviews\n",
      "6. Greens &amp; Gravy ($$): 3.5 stars based on 93 reviews\n",
      "7. Colonnade Restaurant ($$): 4.0 stars based on 350 reviews\n",
      "8. South City Kitchen Buckhead ($$): 4.5 stars based on 248 reviews\n",
      "9. Poor Calvin’s ($$): 4.5 stars based on 1558 reviews\n",
      "10. Rock’s Chicken &amp; Fries ($): 4.0 stars based on 67 reviews\n",
      "\n",
      "(Passed!)\n"
     ]
    }
   ],
   "source": [
    "# Test cell: `rankings_test`\n",
    "\n",
    "assert type(rankings) is list, \"`rankings` must be a list\"\n",
    "assert all([type(r) is dict for r in rankings]), \"All `rankings[i]` must be dictionaries\"\n",
    "\n",
    "print(\"=== Rankings ===\")\n",
    "for i, r in enumerate(rankings):\n",
    "    print(\"{}. {} ({}): {} stars based on {} reviews\".format(i+1,\n",
    "                                                             r['name'],\n",
    "                                                             r['price'],\n",
    "                                                             r['stars'],\n",
    "                                                             r['numrevs']))\n",
    "\n",
    "assert rankings[0] == {'numrevs': 549, 'name': 'Gus’s World Famous Fried Chicken', 'stars': '4.0', 'price': '$$'}\n",
    "assert rankings[1] == {'numrevs': 1777, 'name': 'South City Kitchen - Midtown', 'stars': '4.5', 'price': '$$'}\n",
    "assert rankings[2] == {'numrevs': 2241, 'name': 'Mary Mac’s Tea Room', 'stars': '4.0', 'price': '$$'}\n",
    "assert rankings[3] == {'numrevs': 481, 'name': 'Busy Bee Cafe', 'stars': '4.0', 'price': '$$'}\n",
    "assert rankings[4] == {'numrevs': 108, 'name': 'Richards’ Southern Fried', 'stars': '4.0', 'price': '$$'}\n",
    "assert rankings[5] == {'numrevs': 93, 'name': 'Greens &amp; Gravy', 'stars': '3.5', 'price': '$$'}\n",
    "assert rankings[6] == {'numrevs': 350, 'name': 'Colonnade Restaurant', 'stars': '4.0', 'price': '$$'}\n",
    "assert rankings[7] == {'numrevs': 248, 'name': 'South City Kitchen Buckhead', 'stars': '4.5', 'price': '$$'}\n",
    "assert rankings[8] == {'numrevs': 1558, 'name': 'Poor Calvin’s', 'stars': '4.5', 'price': '$$'}\n",
    "assert rankings[9] == {'numrevs': 67, 'name': 'Rock’s Chicken &amp; Fries', 'stars': '4.0', 'price': '$'}\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b3bde66e454dc063",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Fin!** This cell marks the end of Part 1. Don't forget to save, restart and rerun all cells, and submit it. When you are done, proceed to Part 2."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
